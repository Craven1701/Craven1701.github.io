---
title: 【爬虫基础·一】:有关网络请求与网页结构的基础知识
published: true
tags: python爬虫
categories: 
---

本章基于《Python3 网络爬虫开发实战 崔庆才 》第二章:爬虫基础

## HTTP基本原理

### URL与URI
**URI：**全称为UniformResourceIdentifier统一资源标识符
**URL**：全称为UniversalResourceLocator,即统一资源定位符。

URL是URI的子集,也就是说每个URL都是URI,但不是每个URI都是URL。

URI=URL+URN(UniversalResourceName）

###http与https协议
URL的开头会有http或https,这就是访问资源需要的协议类型。有时,我们还会看到ftp、sftp、smb开头的URL,它们都是协议类型。)
HTTP的全称是HyperTextTransferProtocol,中文名叫作超文本传输协议。
HTTPS的全称是HyperTextTransferProtocoloverSecureSocketLayer,是以安全为目标的HTTP通道,简单讲是HTTP的安全版,即HTTP下加入SSL层,简称为HTTPS。HTTPS的安全基础是SLL因此通过它传输的内容都是经过SSL加密的。

### http请求过程与Inspect-network表格解读

|列名|内容|
|---|---|
|Name|请求的名称,一般会将URL的最后一部分内容当作名称。|
|Status|响应的状态码,这里显示为200,代表响应是正常的。通过状态码,我们可以判断发送了请求之后是杏得到了正常的响应。|
|Type|请求的文梢类型。这里为document,代表我们这次请求的是一个HTML文档,内容就是一些HTML代码。|
|Initiator|请求源。用来标记请求是由哪个对象或进程发起的。|
|Size|从服务器下载的文件和请求的资源大小。如果是从缓存中取得的资源,则该列会fromcache。|
|Time|发起请求到获取响应所用的总时间。|
|WaterFall|网络请求的可视化瀑布流。|

#### http请求的内容
![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 14.23.55.png)
|Genral||
|---|---|
|Request URL||
|Request Method||
|Status Code||
|Remote Address||
|Referrer Policy||


|Response Headers||
|---|---|
|||


|Request Headers||
|---|---|
|||

### 请求的组成
1. Request Method 
2. Request URL
3. Request Headers
4. Request Body

### 1. Request Method：GET POST
G E T和P O S T 请求方法有如下区别。
- G E T请求中的参数包含在U R L里面,数据可以在U R L中看到,而P O S T 请求的U R L不会包含这些数据,数据都是通过表单形式传输的,会包含在请求体中。
- G E T请求提交的数据最多只有1 0 2 4 字节,而P O S T 方式没有限制。

#### 其他请求方法描


|方法|描述|
|---|---|
|GET|述请求页面,并返回页面内容|
|HEAD|类似于G E T请求,只不过返回的响应中没有具体的内容,用于获取报头|
|POST|大多用于提交表单或上传文件,数据包含在请求体中|
|PUT|从客户端向服务器传送的数据取代指定文梢中的内容|
|DELETE|请求服务器删除指定的页面(?客户端还有这中嚣张的权限啊。)|
|CONNECT|把服务器当作跳板,让服务器代替客户端防问其他网页(懂了，梯子的基础是吧。)|
|OPTIONS|允许客户端查看服务器的性能|
|TRACE|回显服务器收到的请求,主要用于测试或诊断|

### 2.Request URL 
这个没什么好说的

### 3.Requestheader
请求头,用来说明`服务器要使用的`附加信息,比较重要的信息有Cookie、Referer、User-Agent等。因此,请求头是请求的重要组成部分,在写爬虫时,大部分情况下都需要设定请求头。

####一些常用的头信息
|名称|内容|
|---|---|
|Accept|请求报头域,用于指定客户端可接受哪些类型的信息。|
|Accept-Language:|指定客户端可接受的语言类型|
|Accept-Encoding|:指定客户端可接受的内容编码|
|Host:|用于指定请求资源的主机IP和端- 号,其内容为请求URL的原始服务器或网关的位置。从HTTP1.l版本开始,请求必须包含此内容。|
|Cookie|也常用复数形式Cookies,这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。它的主要功能是维持当前访问会话。例如,我们输入用户名和密码成功登录某个网站后,服务器会用会话保存登录状态信息,后面我们每次刷新或请求该站点的其他页面时,会发现都是登录状态,这就是Cookies的功劳。Cookies里有信息标识了我们所对应的服务器的会话,每次浏览器在请求该站点的页面时,都会在请求头中加上Cookies并将其发送给服务器,服务器通过Cookies识别出是我们自己,并且查出当前状态是登录状态,所以返回结果就是登录之后才能看到的网页内容。|
|Referer:|此内容用来标识这个请求是从哪个页面发过来的,服务器可以拿到这一信息并做相应的处理,如做来源统计、防盗链处理等。|
|User-Agent:|简称UA,它是一个特殊的字符串头,可以使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。在做爬虫时加上此信息,可以伪装为浏览器;如果不加,很可能会被识别州为爬虫。|
|Content-Type|也叫互联网媒体类型(InternetMediaType)或者MIME类型,在HTTP协议消息头中,它用来表示具体请求中的媒体类型信息。例如,text/html代表HTML格式,image/gif代表GIF图片,application/json代表JSON类型,更多对应关系可以查看此对照表:http://tool.oschina.net/commons (GET一般是不用设置提交类型的吧？)|

### 4.Request Body 
请求体般承载的内容是POST 请求中的表单数据,而对于GET请求,请求体则为空。

### 响应的组成
1. Response Status Code

  这个单独成为一篇文，叫做“响应状态码清单”

2. Response Headers

	- Date:标识响应产生的时间。

	- Last-Modified:指定资源的最后修改时间。

	- Content-Encoding:指定响应内容的编码。

	- Server:包含服务器的信息,比如名称、版本号等。

	- Content-Type:文档类型,指定返回的数据类型是什么,如text/html代表返回HTML文档,application/x-javascript!J!U代表返回JavaScript文件,image/jpeg则代表返回图片。

	- Set-Cookie:设置Cookies。响应头中的Set-Cookie告诉浏览器需要将此内容放在Cookies中,下次请求携带Cookies请求。

	- Expires:指定响应的过期时间,可以使代理服务器或浏览器将加载的内容更新到缓存巾。如果再次访问时,就可以直接从缓存中加载,降低服务器负载,缩短加载时间。

3. Response Body

   打开控制台，选中一个响应记录，按`preview`查看响应体。

   爬虫获得响应后，接下来最重要的一步就是解析响应体。

## 网页基础

网页的基本组成元素

1. HTML: Hyper Text Markup Language 超文本标记语言

   CSS: Cascading Style Sheet 层叠式样表（皮肤，都是皮肤）

3. JavaScript: 定义行为

### HTML相关知识


1. 一个网页的标准形式是html 标签内嵌套head 和body 标签 ,head内定义网页的配置和引用,body内定义网页的正文。

```html
<!DOCTYPE html> 
<html>
  <head> 
    <meta charset="UTF-8"> 
    <title>This is a Demo</title> 
  </head> 
  <body>
    <div id="container"> 
      <div class="rapper">
           <h2 class =”title”>Hello World</h2>
        <p class="text"> Hello, this is a paragraph.</p> 
      </div> 
    </div> 
  </body> 
</html>
```

2. **节点树与DOM**

在HTML中,所有标签定义的内容都是节点,它们构成了一个HTMLDOM树。**HTML文档中所有的内容都是节点！！！**

我们先看下什么是DOM。DOM是W3C(万维网联盟)的标准,其英文全称DocumentO均巳ctModel,即文档对象模型。它定义了访问HTML和XML文档的标准:

![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 15.29.03.png)

#### 节点树结构

![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 15.27.53.png)

**通过HTMLDOM,树中的所有节点均可通过J a v aS c r i p t 访问,所有HTML节点元素均可被修改,也可以被创建或删除。**

#### CSS选择器
![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 15.33.09.png)
![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 15.34.02.png)
![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 15.35.02.png)

## 爬虫的基本原理

### 1.获取网页

### 2.提取信息

### 3.保存信息

### 4.自动化程序



## 会话和Cookies

### 静态网页与动态网页
网页的内容是H T M L代码编写的,文字、图片等内容均通过写好的H T M L代码来指定,这种页面叫作静态网页。
它加载速度快,编写简单,但是存在很大的缺陷,如可维护性差,不能根据U R L 灵活多变地显示内容等。例如,我们想要给这个网页的U R L传入一个n a m e 参数,让其在网页中显示出来,是无法做到的。
因此,动态网页应运而生,它可以动态解析U R L中参数的变化,关联数据库井动态呈现不同的页面内容,非常灵活多变。 我们现在遇到的大多数网站都是动态阿站,它们不再是一个简单的H T M L,而是可能由J S P、P H P、P y t h o n 等语言编写的,其功能比静态网页强大和丰富太多了。

### 会话与Cookie

http本身是无状态的，利用cookie实现的会话维持。
#### 会话
而在W e b中,会话对象用来存储特定用户会话所需的属性及配置信息。 这样,当用户在应用程序的W e b页之间跳转时,存储在会话对象中的变量将不会丢失,而是在整个用户会话中一直存在下去。

#### Cookie的状态维持
那么,我们怎样利用Cookies保持状态呢?当客户端第一次请求服务器时,服务器会返回一个请求头中带有Set-Cookie字段的响应给客户端,用来标记是哪一个用户,客户端浏览器会把Cookies保•存起来。当浏览器下一次再请求该网站时,浏览器会把此Cookies放到请求头一起提交给服务器,“Cookies携带了会话ID信息,服务器检查该Cookies即可找到对应的会话是什么,然后再判断会话来以此来辨认用户状态。在成功登录某个网站时,服务器会告诉客户端设置哪些Cookies信息,在后续访问页面时客户端会把Cookies发送给服务器,服务器再找到对应的会话加以判断。如果会话中的某些设置登录状态的变量是有效的,那就证明用户处于登录状态,此时返回登录之后才可以查看的网页内容,浏览器再进行解析便可以看到了。反之,如果传给服务器的Cookies是无效的,或者会话已经过期了,我们将不能继续访问页面,此时可能会收到错误的响应或者跳转到登录页面重新登录。所以,Cookies和会话需要配合,一个处于客户端,一个处于服务端,二者共同协作,就实现了登录会话控制。

**在浏览器控制台中查看Cookie的内容**
接下来,我们来看看Cookies都有哪些内容。这里以知乎为例,在浏览器开发者工具中打开Application选项卡,然后在左侧会有一个Storage部分,最后一项即为Cookies,将其点开,如图2-13所示,这些就是Cookies。

#### Cookies的基本属性介绍
|属性|介绍|
|---|---|
|Name|该Cookie的名称。一旦创建,该名称便不可更改。|
|Value|该Cookie的值。如果值为Unicode字符,需要为字符编码。如果值为二进制数据,则需要使用BASE64编码。|
|Domain|可以访问该Cookie的域名。例如,如果设置为.zhihu.com,则所有以zhihu.com结尾的域名都可以访问该Cookie。|
|MaxAge|该Cookie失效的时间,单位为秒,也常和Expires一起使用,通过它可以计算「I\其有效时间。MaxAge如果为正数,贝lj该Cookie在MaxAge秒之后失效。如果为负数,则关闭浏览器时Cookie即失效,浏览器也不会以任何形式保存该Cookie。|
|Path|该Cookie的使用路径。如果设置为/path/,则只有路径为/path/的页面可以访问该Cookie。如果设置为人则本域名下的所有页面都可以访问该Cookie|
|Size|此Cookie的大小。|
|HTTP|Cookie的httponly属性。<br/>若此属性为true,则只有在HTTP头中会带有此Cookie的信息,而不能通过document.cookie来访问此Cookie。|
|Secure|该Cookie是否仅被使用安全协议传输。安全协议有HTTPS和SSL等,在网络上传输数据之前先将数据加密。默认为false。|

从表面意思来说,会话Cookie就是把Cookie放在浏览器内存里,浏览器在关闭之后该Cookie即失效;
持久Cookie则会保存到客户端的硬盘中,下次还可以继续使用,用于长久保持用户登录状态。
但是讲到底，这玩意到底能不能用，最主要的是`MaxAge`字段的时效到底设置了多久。

![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 15.53.47.png)



## 代理的基本原理

### 1. 基本原理

代理实际上指的就是代理服务器,英文叫作proxyserver,它的功能是代理网络用户去取得网络信息。形象地说,它是网络信息的中转站。在我们正常请求一个网站时,是发送了请求给Web服务器,Web服务器把响应传回给我们。如果设置了代理服务器,实际上就是在本机和服务器之间搭建了一个桥,此时本机不是直接向Web服务器发起请求,而是向代理服务器发出请求,请求会发送给代理服务器,然后由代理服务器再发送给Web服务器,接着由代理服务器再把Web服务器返回的响应转发给木机。这样我们同样可以正常访问网页,但这个过程中Web服务器识别出的真实IP就不再是我们本机的IP了,就成功实现了IP伪装,这就是代理的基本原理。

（这就是梯子基础吗？）

隐藏真实IP:上网者也可以通过这种方法隐藏向己的IP,免受攻击。对于爬虫来说,我们用代理就是为了隐藏向身IP,防止向身的IP被封锁。

### 2. 代理分类

![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 16.00.35.png)
![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 16.00.58.png)
![](/Users/ncc-1701-enterprise/Desktop/Screen Shot 2021-02-24 at 16.01.08.png)

